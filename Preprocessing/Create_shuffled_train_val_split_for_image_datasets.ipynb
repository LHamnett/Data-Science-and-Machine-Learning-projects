{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final -Create shuffle train val split for train (>10,000 images).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6oGHf1bj7sA"
      },
      "source": [
        "##  Building training and validation image sets for a data driven contest\n",
        "\n",
        "### Author/ML Engineer: Leon Hamnett - [linkedIn](https://www.linkedin.com/in/leon-hamnett/)\n",
        "\n",
        "\n",
        "\n",
        "### Introduction:\n",
        "\n",
        "As part of a team of machine learning engineers, I took part in a [datadriven contest](https://https-deeplearning-ai.github.io/data-centric-comp/) organised by Andrew Ng (a well known machine learning teacher and researcher). The aim of this competition was to focus on methods to improve dataset quality as opposed to improving the machine learning model itself. \n",
        "\n",
        "During this contest we created a number of different image datasets using such methods as cleaning and relabelling the existing dataset, creating synthetic data and applying a number of different image transforms and augmentations on the images. \n",
        "\n",
        "As each submission could only contain a maximum of 10,000 images, it was necessary to shuffle all of our image datasets together and select 10,000 images to be included in the training and validation image datasets.\n",
        "\n",
        "This notebook was used to randomly choose 10,000 images from a number of different folders containing different image datasets, aiming for a balanced number of images in each class (10 classes total).\n",
        "\n",
        "### Importing libaries:\n",
        "\n",
        "During this notebook, we rely heavily on the shutil and os libaries for file and folder manipulations, as well as implementing the code in an efficient way to ensure that the shuffling and copying of images into new datasets can be completed as quickly as possible.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQSY7HgCxcsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70bb4237-690c-49e9-a468-6ef3bfbb0ecf"
      },
      "source": [
        "#import the libaries\n",
        "import shutil\n",
        "import numpy as np\n",
        "import os\n",
        "from os import getcwd\n",
        "import shutil\n",
        "!pip3 install pyfastcopy\n",
        "import pyfastcopy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyfastcopy in /usr/local/lib/python3.7/dist-packages (1.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14ng8pFkpt2B",
        "outputId": "0cef6bf8-026e-41b4-cd11-0d2264a96e66"
      },
      "source": [
        "#mount google drive so we can access the files and folders with all our images\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVgwLuDXFOjr",
        "outputId": "05a4db8a-38b3-4c88-c99f-18b99177f1c2"
      },
      "source": [
        "#check where the current working directory is located\n",
        "print(getcwd())\n",
        "image_dir = '/content/drive/MyDrive/Datadriven_contest/Image_datasets'\n",
        "shuffled_dir = os.path.join(image_dir,'shuffled_temp')\n",
        "numerals = ['i', 'ii', 'iii', 'iv','v', 'vi', 'vii', 'viii', 'ix', 'x'] #list of numerals to create folders, each numeral is an image class"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2WtJ3QB8QyM"
      },
      "source": [
        "### Creating the folder structure:\n",
        "\n",
        "Firstly we will create the folder structure to copy the images into for our newly shuffled and created dataset. If the folder structure already exists from previous iterations, we delete it and we start with empty folders again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kwqOCo-qKSh",
        "outputId": "e507932a-2ce3-4e7a-d446-f7e9f5fa5145"
      },
      "source": [
        "#make a new temp directory\n",
        "if os.path.exists(shuffled_dir) == True: #check if folder already exists\n",
        "  print('Deleting existing shuffled_temp directory')\n",
        "  shutil.rmtree(shuffled_dir) #delete folder\n",
        "  print('making new shuffled temp directory')\n",
        "  os.mkdir(shuffled_dir) #create folder\n",
        "else:\n",
        "  print('making new shuffled temp directory')\n",
        "  os.mkdir(shuffled_dir)\n",
        "\n",
        "#make new train and valid directories\n",
        "new_train_dir = os.path.join(shuffled_dir,'train')\n",
        "os.mkdir(new_train_dir)\n",
        "new_valid_dir = os.path.join(shuffled_dir,'val')\n",
        "os.mkdir(new_valid_dir)\n",
        "\n",
        "#make numeral/class sub folders for both train and validation sets\n",
        "for folder in os.listdir(shuffled_dir): \n",
        "    for x in numerals:\n",
        "      folder_to_make_temp = os.path.join(shuffled_dir,folder,x)\n",
        "      os.mkdir(folder_to_make_temp)\n",
        "      print('Created {} numeral: {}'.format(folder,x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting existing shuffled_temp directory\n",
            "making new shuffled temp directory\n",
            "Created train numeral: i\n",
            "Created train numeral: ii\n",
            "Created train numeral: iii\n",
            "Created train numeral: iv\n",
            "Created train numeral: v\n",
            "Created train numeral: vi\n",
            "Created train numeral: vii\n",
            "Created train numeral: viii\n",
            "Created train numeral: ix\n",
            "Created train numeral: x\n",
            "Created val numeral: i\n",
            "Created val numeral: ii\n",
            "Created val numeral: iii\n",
            "Created val numeral: iv\n",
            "Created val numeral: v\n",
            "Created val numeral: vi\n",
            "Created val numeral: vii\n",
            "Created val numeral: viii\n",
            "Created val numeral: ix\n",
            "Created val numeral: x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzXThyI-8qv9"
      },
      "source": [
        "### Check how many images we have:\n",
        "\n",
        "Now we count how many images we have in all of the different folders we want to shuffle. We unzip an image dataset if it has been uploaded to gdrive in a .zip format. \n",
        "\n",
        "Next we go through all of the folders and we count the images that are in each class for each folder and we keep a running total of the images we have per class, as well as the total number of images. \n",
        "\n",
        "This also serves as a sanity check, to make sure that the code is actually looking through the folders correctly and will be able to copy the images at a later time. This would also flag any empty folders or missing classes which we could rectify as needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3PL--NjFi3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee68b34e-e355-4e8d-93d6-ddf8f1e65148"
      },
      "source": [
        "# #unzip folders if needed. Syntax: !unzip zipped_file -d folder_to_unzip_to\n",
        "# os.chdir(image_dir)\n",
        "# !unzip \"augmented_shift_rotate.zip\" -d \"aug_shift_rotate\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  augmented_shift_rotate.zip\n",
            "replace aug_shift_rotate/data_modified/rotation/ii/rot_0_5733.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4kratFc94SH"
      },
      "source": [
        "Next we choose from all of our image folders the images that we would like to shuffle into our training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7FhxDmUqWOL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "109fbf0a-d70d-4f8c-b32d-31f2213f855a"
      },
      "source": [
        "#Choose folders to include (reference directory with i,ii,iii etc folders)\n",
        "baseline = os.path.join(image_dir,'baseline/baseline/combined_train_val_baseline')\n",
        "image_gen = os.path.join(image_dir,'image_gen/image_gen')\n",
        "augmented_zoom = os.path.join(image_dir,'augmented_zoom_flip/Zoom')\n",
        "augmented_flip = os.path.join(image_dir,'augmented_zoom_flip/Flip')\n",
        "augmented_thresh = os.path.join(image_dir,'augmented_thresh')\n",
        "augmented_blur = os.path.join(image_dir,'augmented_blur')\n",
        "image_gen2 = os.path.join(image_dir,'image_gen2_curls_aug_transl')\n",
        "image_gen3 = os.path.join(image_dir,'image_gen3_no_aug')\n",
        "image_gen4 = os.path.join(image_dir,'image_gen4_no_aug')\n",
        "test = os.path.join(image_dir,'baseline/baseline/test/label_book')\n",
        "final = os.path.join(image_dir,'processed_images_01_train_val')\n",
        "final2 = os.path.join(image_dir,'processed_images_02')\n",
        "shuf_temp_train = os.path.join(image_dir,'shuffled_temp/train')\n",
        "shuf_temp_val = os.path.join(image_dir,'shuffled_temp/val')\n",
        "shuffled_temp = os.path.join(image_dir,'processed_images_02_train_val/val')\n",
        "processed3 = os.path.join(image_dir,'processed_images_03')\n",
        "augmented_shift = os.path.join(image_dir,'aug_shift_rotate/data_modified/shift')\n",
        "augmented_rotate = os.path.join(image_dir,'aug_shift_rotate/data_modified/rotation')\n",
        "processed4 = os.path.join(image_dir,'processed_images_04/train')\n",
        "\n",
        "#folders_to_shuffle = [processed3,augmented_zoom,augmented_flip,augmented_thresh,augmented_blur,augmented_shift,augmented_rotate] \n",
        "folders_to_shuffle = [processed4]\n",
        "\n",
        "#init counters for images totals\n",
        "total_images,num_1s,num_2s,num_3s,num_4s,num_5s,num_6s,num_7s,num_8s,num_9s,num_10s = [0]*11 #init counters\n",
        "totals = [total_images,num_1s,num_2s,num_3s,num_4s,num_5s,num_6s,num_7s,num_8s,num_9s,num_10s] #make list of counters\n",
        "\n",
        "#for each folder loop through numeral folder and count images inside\n",
        "for folder in folders_to_shuffle:\n",
        "  for numeral in range(len(numerals)):\n",
        "    try:\n",
        "      temp_folder = os.path.join(folder,numerals[numeral]) #set folder location as the one we are looking at\n",
        "      temp_count = len(os.listdir(temp_folder)) #count nuber of images\n",
        "      totals[numeral+1]+=temp_count #add image number to relevant class counter\n",
        "      totals[0]+=temp_count #add image number to totals\n",
        "    except:\n",
        "      continue\n",
        "    print('folder {} numeral {} count: {} total: {}'.format(folder,numeral+1,temp_count,totals[0]))\n",
        "\n",
        "#print totals once counting is finished\n",
        "print(totals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "folder /content/drive/MyDrive/Datadriven_contest/Image_datasets/processed_images_04/train numeral 1 count: 2390 total: 2390\n",
            "folder /content/drive/MyDrive/Datadriven_contest/Image_datasets/processed_images_04/train numeral 2 count: 2005 total: 4395\n",
            "folder /content/drive/MyDrive/Datadriven_contest/Image_datasets/processed_images_04/train numeral 3 count: 1700 total: 6095\n",
            "folder /content/drive/MyDrive/Datadriven_contest/Image_datasets/processed_images_04/train numeral 4 count: 1885 total: 7980\n",
            "folder /content/drive/MyDrive/Datadriven_contest/Image_datasets/processed_images_04/train numeral 5 count: 1911 total: 9891\n",
            "folder /content/drive/MyDrive/Datadriven_contest/Image_datasets/processed_images_04/train numeral 6 count: 1637 total: 11528\n",
            "folder /content/drive/MyDrive/Datadriven_contest/Image_datasets/processed_images_04/train numeral 7 count: 1599 total: 13127\n",
            "folder /content/drive/MyDrive/Datadriven_contest/Image_datasets/processed_images_04/train numeral 8 count: 1628 total: 14755\n",
            "folder /content/drive/MyDrive/Datadriven_contest/Image_datasets/processed_images_04/train numeral 9 count: 1719 total: 16474\n",
            "folder /content/drive/MyDrive/Datadriven_contest/Image_datasets/processed_images_04/train numeral 10 count: 2078 total: 18552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93pY-i3T-V5T"
      },
      "source": [
        "### Shuffling images and copying images to make new dataset:\n",
        "\n",
        "Now we randomly choose an appropiate number of training and validation images from all of the above folders and we copy them into our empty folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptrk_nEAxcsR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55974a84-8c6d-4562-e2dd-e465472fc27c"
      },
      "source": [
        "#choose number of images from each folder and shuffle into train valid\n",
        "for folder in folders_to_shuffle:\n",
        "  temp_folder_path = os.path.join(image_dir,folder) #make path to folder\n",
        "  print(temp_folder_path)\n",
        "  for numeral in numerals: #loop through numerals/classes\n",
        "      print('starting numeral {}'.format(numeral))\n",
        "      try: # catch exceptions that are not images\n",
        "        temp_num_path = os.path.join(temp_folder_path,numeral) #set path to each folder containing a set of numerals\n",
        "        temp_image_list = os.listdir(temp_num_path) #get list of images\n",
        "        total_images_in_folder = len(temp_image_list) #get number of images\n",
        "        \n",
        "        #get indexes from image list and assign to train/valid sets\n",
        "        if total_images_in_folder > 1000: #if we have more than 1000 images for each numeral, choose less so only 1000 are chosen for each of the 10 classes\n",
        "          num_train_images = int(900) #set 90% of images as train, rest validation\n",
        "          num_val_images = int(100)\n",
        "        else: #if we have less than 1000 images per class, just take all the images\n",
        "          num_train_images = int(total_images_in_folder * 0.9)\n",
        "          num_val_images = int(total_images_in_folder * 0.1)\n",
        "\n",
        "        #create list of indexes corresponding to an image, choose indices as validation and train\n",
        "        val_indexes_to_copy = np.random.choice(np.arange(len(temp_image_list)),size=num_val_images,replace=False) #randomly choose 10% of images as validation\n",
        "        train_all = [x for x in np.arange(len(temp_image_list)) if x not in val_indexes_to_copy] #choose indices not in validation set\n",
        "        train_indexes_to_copy = np.random.choice(train_all,size=num_train_images,replace=False) # from indices not in val set, choose appropiate number of train images\n",
        "\n",
        "        #process/copy train_images\n",
        "        for index in train_indexes_to_copy: #loop through the training indices\n",
        "          try:\n",
        "                temp_img_path = os.path.join(temp_folder_path,numeral,temp_image_list[index]) #get image path\n",
        "                copy_path = os.path.join(new_train_dir,numeral,temp_image_list[index]) #make path to copy image\n",
        "                shutil.copy2(temp_img_path,copy_path) #copy into relevant train folder\n",
        "                #!cp $temp_img_path $copy_path\n",
        "                # with open(temp_img_path, 'rb') as fin:\n",
        "                #   with open(copy_path, 'wb') as fout:\n",
        "                #     shutil.copyfileobj(fin, fout, 128*1024)\n",
        "          except Exception as e: \n",
        "              print(e)\n",
        "              continue\n",
        "\n",
        "        print('numeral {} train images finished copying'.format(numeral))\n",
        "\n",
        "        #process valid_images\n",
        "        for index in val_indexes_to_copy:\n",
        "          try:\n",
        "                temp_img_path = os.path.join(temp_folder_path,numeral,temp_image_list[index]) #get image path\n",
        "                copy_path = os.path.join(new_valid_dir,numeral,temp_image_list[index])\n",
        "                shutil.copy2(temp_img_path,copy_path) #copy into relevant valid folder\n",
        "          except Exception as e: \n",
        "              print(e)\n",
        "              continue\n",
        "        print('numeral {} valid images finished copying'.format(numeral))\n",
        "\n",
        "      except Exception as e:\n",
        "          print(e)\n",
        "          continue\n",
        "      \n",
        "      print(numeral, ' numeral has finished shuffling')\n",
        "print('all numerals and folders finished')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Datadriven_contest/Image_datasets/processed_images_04/train\n",
            "starting numeral i\n",
            "numeral i train images finished copying\n",
            "numeral i valid images finished copying\n",
            "i  numeral has finished shuffling\n",
            "starting numeral ii\n",
            "numeral ii train images finished copying\n",
            "numeral ii valid images finished copying\n",
            "ii  numeral has finished shuffling\n",
            "starting numeral iii\n",
            "numeral iii train images finished copying\n",
            "numeral iii valid images finished copying\n",
            "iii  numeral has finished shuffling\n",
            "starting numeral iv\n",
            "numeral iv train images finished copying\n",
            "numeral iv valid images finished copying\n",
            "iv  numeral has finished shuffling\n",
            "starting numeral v\n",
            "numeral v train images finished copying\n",
            "numeral v valid images finished copying\n",
            "v  numeral has finished shuffling\n",
            "starting numeral vi\n",
            "numeral vi train images finished copying\n",
            "numeral vi valid images finished copying\n",
            "vi  numeral has finished shuffling\n",
            "starting numeral vii\n",
            "numeral vii train images finished copying\n",
            "numeral vii valid images finished copying\n",
            "vii  numeral has finished shuffling\n",
            "starting numeral viii\n",
            "numeral viii train images finished copying\n",
            "numeral viii valid images finished copying\n",
            "viii  numeral has finished shuffling\n",
            "starting numeral ix\n",
            "numeral ix train images finished copying\n",
            "numeral ix valid images finished copying\n",
            "ix  numeral has finished shuffling\n",
            "starting numeral x\n",
            "numeral x train images finished copying\n",
            "numeral x valid images finished copying\n",
            "x  numeral has finished shuffling\n",
            "all numerals and folders finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35hB2h4K_a3A"
      },
      "source": [
        "Now we have obtained our new shuffled and copied dataset.\n",
        "\n",
        "It should be noted that the above code has been optimised for copying images in an as efficient manner as possible. \n",
        "\n",
        "Firstly, instead of using a list of filenames and randomly choosing from this list, we use a list of indices. It is much quicker to shuffle and choose elements from a list of integers than a list of long strings representing filenames. Once we have a list of numbers, representing the images we want to choose, it is a simple matter to pass each integer as an index for the list of images and get our images in this fashion.\n",
        "\n",
        "Secondly, the copying operation itself has been optimised. There are a number of different functions which were analysed:\n",
        "1. shutil copy2 function: ```shutil.copy2(temp_img_path,copy_path)``` \n",
        "2. Using the command line cp function \n",
        "``` !cp $temp_img_path $copy_path```\n",
        "3. writing the images directly: \n",
        "```\n",
        "with open(temp_img_path, 'rb') as fin: \n",
        "    with open(copy_path, 'wb') as fout: \n",
        "      shutil.copyfileobj(fin, fout, 128*1024) \n",
        "    ```\n",
        "         \n",
        "After some experimentation and iteration, it was found that using the shututil copy2 function with python fast copy package installed was the quickest and most efficient way to copy a large number of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0JEzm-qcFKJu"
      },
      "source": [
        "#if needed zip the new dataset\n",
        "os.chdir(image_dir)\n",
        "!zip -r processed_images_01_train_val.zip processed_images_01_train_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEow5MVqHWNj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}